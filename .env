# Your DataRobot API token.
# Refer to https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#configure-your-environment for help.
DATAROBOT_API_TOKEN=NjkyMmM5Mjc1NjczYzFmZjc2OGEyNzg2Oi9Gb3FYek5ncHVRbWVTRU1JTUgrc3B5SUxZTTR3WG4yRzdvZGNOMEFQZXc9

# The URL of your DataRobot instance API.
DATAROBOT_ENDPOINT=https://datarobot-lab.po-cto.dell.com/api/v2/

# The Pulumi stack name to use for this project.
# PULUMI_STACK_NAME=dev

# If empty, a blank passphrase will be used
PULUMI_CONFIG_PASSPHRASE=123

# If empty, a new use case will be created
DATAROBOT_DEFAULT_USE_CASE=

# If empty, a new execution environment will be created for each agent using the docker_context folder
DATAROBOT_DEFAULT_EXECUTION_ENVIRONMENT="680fe4949604e9eba46b1775"

# This is set to a specific version of `[DataRobot] Python 3.11 GenAI Agents` to preserve compatibility of the templates
# DATAROBOT_DEFAULT_EXECUTION_ENVIRONMENT_VERSION_ID="680fe4949604e9eba46b1775"

# LLM Configuration:
# Agent templates support multiple flexible LLM options including:
# - LLM Gateway Direct (default)
# - LLM Blueprint with an External LLM
# - Already Deployed Text Generation model in DataRobot
#
# You can edit the LLM configuration by manually changing which configuration is
# active (recommended option).
# Simply run `ln -sf ../configurations/<chosen_configuration> llm.py`
# from the `infra/infra` folder
#
# If you want to do it dynamically however, you can also set it as a configuration value with:
# INFRA_ENABLE_LLM=<chosen_configuration>
# from the list of options in the infra/configurations/llm folder
# Here are some examples of each of those configuration using the dynamic option described above:

# If you want to use the LLM Gateway direct (default)
# INFRA_ENABLE_LLM=gateway_direct.py

# If you want to choose an existing LLM Deployment in DataRobot
# uncomment and configure these:
TEXTGEN_DEPLOYMENT_ID=689cca4777ccb20575aa611f
INFRA_ENABLE_LLM=deployed_llm.py

# If you want to configure an LLM with an external LLM provider
# like Azure, Bedrock, Anthropic, or VertexAI (or all 4). Here we provide
# an Azure AI example, see:
# https://docs.datarobot.com/en/docs/gen-ai/playground-tools/deploy-llm.html
# for details on other providers and details:
# INFRA_ENABLE_LLM=blueprint_with_external_llm.py
# LLM_DEFAULT_MODEL="azure/gpt-4o"
# OPENAI_API_VERSION='2024-08-01-preview'
# OPENAI_API_BASE='https://<your_custom_endpoint>.openai.azure.com'
# OPENAI_API_DEPLOYMENT_ID='<your deployment_id>'
# OPENAI_API_KEY='<your_api_key>'


# MCP servers configuration file
MCP_SERVERS_CONFIG_PATH=agent_langgraph/custom_model/mcp_servers.json
